<project heartbeat-interval="1" index="pi_EMPTY" luaroot="@ESP_PROJECT_OUTPUT@/luaroot" name="pose_estimation_with_onnx" pubsub="auto" threads="8" use-tagged-token="true">
  <description><![CDATA[This example demonstrates how you can use an ONNX model to detect keypoints of a person in an incoming video stream. It uses pose estimation, which is a computer vision technique for recognizing and categorizing the positions of a human.]]></description>
  <metadata>
    <meta id="studioUploadedBy">anonymousUser</meta>
    <meta id="studioUploaded">1750064099860</meta>
    <meta id="studioModifiedBy">anonymousUser</meta>
    <meta id="studioModified">1750067020008</meta>
    <meta id="layout">{"contquery":{"w_annotate":{"x":50,"y":535},"w_counter":{"x":50,"y":665},"w_data":{"x":290,"y":50},"w_object_tracker_array":{"x":50,"y":420},"w_postprocess":{"x":50,"y":295},"w_reader":{"x":50,"y":50},"w_score":{"x":50,"y":175}}}</meta>
    <meta id="studioTags">Example</meta>
  </metadata>
  <properties>
    <property name="PUBLISH_WIDTH"><![CDATA[1280]]></property>
    <property name="PUBLISH_HEIGHT"><![CDATA[720]]></property>
    <property name="MODEL_WIDTH"><![CDATA[640]]></property>
    <property name="MODEL_HEIGHT"><![CDATA[640]]></property>
  </properties>
  <contqueries>
    <contquery name="contquery">
      <windows>
        <window-source index="pi_EMPTY" insert-only="true" name="w_data">
          <description><![CDATA[w_data is a Source window. This is where video frames enter the project.]]></description>
          <schema>
            <fields>
              <field key="true" name="id" type="int64"/>
              <field name="image" type="blob"/>
            </fields>
          </schema>
          <connectors>
            <connector class="videocap" name="video_publisher">
              <properties>
                <property name="type"><![CDATA[pub]]></property>
                <property name="blocksize"><![CDATA[1]]></property>
                <property name="filename"><![CDATA[@ESP_PROJECT_HOME@/test_files/video.mp4]]></property>
                <property name="publishformat"><![CDATA[wide]]></property>
                <property name="inputrate"><![CDATA[10]]></property>
                <property name="repeatcount"><![CDATA[999]]></property>
                <property name="resize_x"><![CDATA[@PUBLISH_WIDTH@]]></property>
                <property name="resize_y"><![CDATA[@PUBLISH_HEIGHT@]]></property>
              </properties>
            </connector>
          </connectors>
        </window-source>
        <window-model-reader model-type="onnx" name="w_reader">
          <description><![CDATA[w_reader is a Model Reader window. This window reads the ONNX model and passes it to the w_score window. Also, pre-processing steps for the incoming events are specified in this window.]]></description>
          <processing-steps>
            <pre name="pre_processing_default">
              <step name="resize">
                <param name="resizeType"><![CDATA[letterbox]]></param>
                <param name="width"><![CDATA[@MODEL_WIDTH@]]></param>
                <param name="height"><![CDATA[@MODEL_HEIGHT@]]></param>
              </step>
              <step name="color">
                <param name="function"><![CDATA[BGR2RGB]]></param>
              </step>
              <step name="normalize">
                <param name="type"><![CDATA[zero_one]]></param>
              </step>
              <step name="encode">
                <param name="shape"><![CDATA[NCHW]]></param>
              </step>
            </pre>
          </processing-steps>
          <parameters>
            <properties>
              <property name="reference"><![CDATA[@ESP_PROJECT_HOME@/analytics/yolov7_pose/yolov7-w6-pose_fp16_io_fp32.onnx]]></property>
              <property name="loggingLevel"><![CDATA[warning]]></property>
              <property name="execProvider"><![CDATA[cuda]]></property>
              <property name="cudaDeviceId"><![CDATA[0]]></property>
            </properties>
          </parameters>
        </window-model-reader>
        <window-score name="w_score">
          <description><![CDATA[w_score is a Score window. This window executes the ONNX modelâ€™s code when data passes through the window.]]></description>
          <schema>
            <fields>
              <field key="true" name="id" type="int64"/>
              <field name="image" type="blob"/>
              <field name="output" type="blob"/>
            </fields>
          </schema>
          <models>
            <offline model-type="onnx">
              <input-map>
                <properties>
                  <property name="images"><![CDATA[image]]></property>
                </properties>
              </input-map>
              <output-map>
                <properties>
                  <property name="detections"><![CDATA[output]]></property>
                </properties>
              </output-map>
            </offline>
          </models>
        </window-score>
        <window-python events="postprocess" output-insert-only="true" name="w_postprocess">
          <description><![CDATA[w_postprocess is a Python window. The Python code in this window converts the model output (tensor format) to more usable formats.]]></description>
          <schema>
            <fields>
              <field name="id" type="int64" key="true"/>
              <field name="_nObjects_" type="int32"/>
              <field name="Object_x" type="array(dbl)"/>
              <field name="Object_y" type="array(dbl)"/>
              <field name="Object_width" type="array(dbl)"/>
              <field name="Object_height" type="array(dbl)"/>
              <field name="Object_score" type="array(dbl)"/>
              <field name="Object_labels" type="string"/>
              <field name="Object_kpts_x" type="array(dbl)"/>
              <field name="Object_kpts_y" type="array(dbl)"/>
              <field name="Object_kpts_score" type="array(dbl)"/>
              <field name="Object_kpts_label_id" type="array(i32)"/>
              <field name="Object_kpts_count" type="array(i32)"/>
              <field name="image" type="blob"/>
            </fields>
          </schema>
          <copy exclude="true"><![CDATA[output]]></copy>
          <use expand="true"><![CDATA[output]]></use>
          <code><![CDATA[
import numpy as np
import sys
sys.path.append("@ESP_PROJECT_HOME@/analytics")
from esp_utils import onnx_tensor, postprocessing

letterbox_image_shape = (@MODEL_HEIGHT@, @MODEL_WIDTH@)
original_image_shape = (@PUBLISH_HEIGHT@, @PUBLISH_WIDTH@)

def postprocess(output):
    event = {}
    output = onnx_tensor.tensor_to_np_array(output)
    event["Object_x"] = []
    event["Object_y"] = []
    event["Object_width"] = []
    event["Object_height"] = []
    
    event["Object_score"] = []
    event["Object_labels"] = ""
    event["Object_kpts_x"] = []
    event["Object_kpts_y"] = []
    event["Object_kpts_score"] = []
    event["Object_kpts_label_id"] = []
    event["Object_kpts_count"] = []

    if len(output.shape) == 1:
        output = output[np.newaxis, :]
    for object_id in range(output.shape[0]):
        x1 = int(output[object_id, 0])
        y1 = int(output[object_id, 1])
        x2 = int(output[object_id, 2])
        y2 = int(output[object_id, 3])
        x, y, w, h = postprocessing.bbox_letterbox_to_original(
            (x1, y1, x2 - x1, y2 - y1), letterbox_image_shape, original_image_shape
        )
        score = output[object_id, 4]


        event["Object_x"].append(float(x))
        event["Object_y"].append(float(y))
        event["Object_width"].append(float(w))
        event["Object_height"].append(float(h))
        event["Object_score"].append(float(score))
        
    
        label = 'person'
        event["Object_labels"] = f"{event['Object_labels']}{label},"

        kpts = output[object_id, 6:].copy()
        count = 0
        for k in range(17):
            (
                kpts[k * 3],
                kpts[k * 3 + 1],
            ) = postprocessing.xy_letterbox_to_original(
                (kpts[k * 3], kpts[k * 3 + 1]),
                letterbox_image_shape,
                original_image_shape,
            )
            conf = float(kpts[k*3+2])
            if conf < 0.3:
                continue
            
            event['Object_kpts_x'].append(float(kpts[k*3]))
            event['Object_kpts_y'].append(float(kpts[k*3+1]))
            event['Object_kpts_score'].append(conf)
            event["Object_kpts_label_id"].append(k)
            count+=1
        event["Object_kpts_count"].append(count)
            
    event["_nObjects_"] = output.shape[0]
    event["Object_labels"] = event["Object_labels"][:-1]
    return event
          ]]></code>
        </window-python>
        <window-object-tracker name="w_object_tracker_array">
          <description><![CDATA[w_object_tracker_array is an Object Tracker window. This window enables you to track objects over time.]]></description>
          <tracker method="bytetrack" track-thresh="0.5" high-thresh="0.6" match-thresh="0.8" velocity-vector-frames="10" max-track-lives="10" track-retention="10"/>
          <output mode="array" tracks="10" keypoints="true" velocity-vector="true"/>
          <input count="_nObjects_" score="Object_score" label="Object_labels" attributes="_Object%_attributes" label-separator="," coord-type="rect" x="Object_x" y="Object_y" width="Object_width" height="Object_height" kpts-count="Object_kpts_count" kpts-x="Object_kpts_x" kpts-y="Object_kpts_y" kpts-score="Object_kpts_score" kpts-label-id="Object_kpts_label_id"/>
        </window-object-tracker>
        <window-counter name="w_counter">
          <description><![CDATA[w_counter is a Counter window. This window provides an indication of the overall performance.]]></description>
        </window-counter>
        <window-custom type="Computer Vision Annotation" version="1" name="w_annotate">
          <description><![CDATA[Annotate the results of an object detection and/or a keypoint detection model.]]></description>
          <schema>
            <fields>
              <field name="id" type="int64" key="true"/>
              <field name="image" type="blob"/>
            </fields>
          </schema>
          <plugin code="@ESP_PROJECT_HOME@/custom_windows/Computer Vision Annotation/Computer Vision Annotation.py">
            <input-map description="Fields related to image and object detection are required. Fields related to keypoints are optional. Object ID (for object tracking) and attributes are also optional.">
              <properties>
                <property name="image" description="Input image (blob)" required="true"><![CDATA[image]]></property>
                <property name="label" description="Delimited list containing the class of the detected objects (string)" required="true"><![CDATA[Object_label]]></property>
                <property name="x" description="Top left X-coordinates of the bounding boxes (array(dbl))" required="true"><![CDATA[Object_x]]></property>
                <property name="y" description="Top left Y-coordinates of the bounding boxes  (array(dbl))" required="true"><![CDATA[Object_y]]></property>
                <property name="w" description="Widths of the bounding boxes (array(dbl))" required="true"><![CDATA[Object_w]]></property>
                <property name="h" description="Heights of the bounding boxes (array(dbl))" required="true"><![CDATA[Object_h]]></property>
                <property name="score" description="Confidence scores array (array(dbl))" required="true"><![CDATA[Object_score]]></property>
                <property name="object_id" description="Tracked object ID, for example from the Object Tracker window (array(i32))"><![CDATA[Object_id]]></property>
                <property name="attribute" description="Delimited list containing the attribute(s) of the detected objects (string)"/>
                <property name="object_track_count" description="Number of tracks per detected object (array(i32))"><![CDATA[Object_track_count]]></property>
                <property name="object_track_kpts_count" description="Number of keypoints per detected object for the track (array(i32))"><![CDATA[Object_track_kpts_count]]></property>
                <property name="object_track_kpts_x" description="X-coordinates for the keypoints track (array(dbl))"><![CDATA[Object_track_kpts_x]]></property>
                <property name="object_track_kpts_y" description="Y-coordinates for the keypoints track (array(dbl))"><![CDATA[Object_track_kpts_y]]></property>
                <property name="object_track_kpts_score" description="Confidence scores for the keypoints track (array(dbl))"><![CDATA[Object_track_kpts_score]]></property>
                <property name="object_track_kpts_label_id" description="Label IDs for the keypoints track (array(i32))"><![CDATA[Object_track_kpts_label_id]]></property>
              </properties>
            </input-map>
            <output-map description="Add an output field, of type `blob`, to store the annotated image. If you use the same image as used in the input variables, the original image is overwritten with an annotated image.">
              <properties>
                <property name="annotated_image" description="Annotated image (blob)"><![CDATA[image]]></property>
              </properties>
            </output-map>
            <initialization description="Set the options for the custom window. Note that either `png` or `jpg` is needed as the value for `output_image_encoding` to display images in Grafana.">
              <properties>
                <property name="input_image_encoding" description="Input image encoding - must be one of the following: `wide`, `jpg`, `png`"><![CDATA[wide]]></property>
                <property name="output_image_encoding" description="Output image encoding - must be one of the following: `wide`, `jpg`, `png`"><![CDATA[jpg]]></property>
                <property name="object_label_separator" description="Object label separator"><![CDATA[,]]></property>
                <property name="kpts_labels" description="Keypoint labels"><![CDATA[nose,l_eye,r_eye,l_ear,r_ear,l_shoulder,r_shoulder,l_elbow,r_elbow,l_wrist,r_wrist,l_hip,r_hip,l_knee,r_knee,l_ankle,r_ankle]]></property>
              </properties>
            </initialization>
          </plugin>
        </window-custom>
      </windows>
      <edges>
        <edge role="data" source="w_data" target="w_score"/>
        <edge role="model" source="w_reader" target="w_score"/>
        <edge source="w_score" target="w_postprocess"/>
        <edge source="w_postprocess" target="w_object_tracker_array"/>
        <edge source="w_object_tracker_array" target="w_annotate"/>
        <edge source="w_annotate" target="w_counter"/>
      </edges>
    </contquery>
  </contqueries>
</project>