<project heartbeat-interval="1" index="pi_EMPTY" luaroot="@ESP_PROJECT_OUTPUT@/luaroot" name="computer_vision_with_onnx" pubsub="auto" threads="8" use-tagged-token="true">
  <metadata>
    <meta id="studioUploadedBy">user1</meta>
    <meta id="studioUploaded">1712839685838</meta>
    <meta id="studioModifiedBy">user1</meta>
    <meta id="studioModified">1712839774544</meta>
    <meta id="layout">{"contquery":{"w_annotate":{"x":330,"y":525},"w_counter":{"x":330,"y":640},"w_data":{"x":330,"y":50},"w_object_tracker":{"x":330,"y":415},"w_postprocess":{"x":330,"y":295},"w_reader":{"x":90,"y":50},"w_score":{"x":330,"y":175}}}</meta>
    <meta id="studioTags">Example</meta>
  </metadata>
  <properties>
    <property name="PUBLISH_WIDTH"><![CDATA[1280]]></property>
    <property name="PUBLISH_HEIGHT"><![CDATA[720]]></property>
    <property name="MODEL_WIDTH"><![CDATA[640]]></property>
    <property name="MODEL_HEIGHT"><![CDATA[640]]></property>
  </properties>
  <contqueries>
    <contquery name="contquery">
      <windows>
        <window-source index="pi_EMPTY" insert-only="true" name="w_data">
          <description><![CDATA[w_data is a Source window. This is where video frames enter the project.]]></description>
          <schema>
            <fields>
              <field key="true" name="id" type="int64"/>
              <field name="image" type="blob"/>
            </fields>
          </schema>
          <connectors>
            <connector class="videocap" name="video_publisher">
              <properties>
                <property name="type"><![CDATA[pub]]></property>
                <property name="inputrate"><![CDATA[10]]></property>
                <property name="repeatcount"><![CDATA[999]]></property>
                <property name="resize_x"><![CDATA[@PUBLISH_WIDTH@]]></property>
                <property name="resize_y"><![CDATA[@PUBLISH_HEIGHT@]]></property>
                <property name="blocksize"><![CDATA[1]]></property>
                <property name="filename"><![CDATA[@ESP_PROJECT_HOME@/test_files/video.mp4]]></property>
                <property name="publishformat"><![CDATA[wide]]></property>
              </properties>
            </connector>
          </connectors>
        </window-source>
        <window-model-reader model-type="onnx" name="w_reader">
          <description><![CDATA[w_reader is a Model Reader window. This window reads the ONNX model and passes it to the w_score window. Also, pre-processing steps for the incoming events are specified in this window.]]></description>
          <processing-steps>
            <pre name="pre_processing_default">
              <step name="resize">
                <param name="resizeType"><![CDATA[letterbox]]></param>
                <param name="width"><![CDATA[@MODEL_WIDTH@]]></param>
                <param name="height"><![CDATA[@MODEL_HEIGHT@]]></param>
              </step>
              <step name="color">
                <param name="function"><![CDATA[BGR2RGB]]></param>
              </step>
              <step name="normalize">
                <param name="type"><![CDATA[zero_one]]></param>
              </step>
              <step name="encode">
                <param name="shape"><![CDATA[NCHW]]></param>
              </step>
            </pre>
          </processing-steps>
          <parameters>
            <properties>
              <property name="reference"><![CDATA[@ESP_PROJECT_HOME@/analytics/yolov7/yolov7-tiny_640x640.onnx]]></property>
              <property name="execProvider"><![CDATA[cuda]]></property>
              <property name="cudaDeviceId"><![CDATA[0]]></property>
            </properties>
          </parameters>
        </window-model-reader>
        <window-score name="w_score">
          <description><![CDATA[w_score is a Score window. This window executes the ONNX modelâ€™s code when data passes through the window.]]></description>
          <schema>
            <fields>
              <field key="true" name="id" type="int64"/>
              <field name="image" type="blob"/>
              <field name="output" type="blob"/>
            </fields>
          </schema>
          <models>
            <offline model-type="onnx">
              <input-map>
                <properties>
                  <property name="images"><![CDATA[image]]></property>
                </properties>
              </input-map>
              <output-map>
                <properties>
                  <property name="output"><![CDATA[output]]></property>
                </properties>
              </output-map>
            </offline>
          </models>
        </window-score>
        <window-python events="postprocess_event" output-insert-only="true" name="w_postprocess">
          <description><![CDATA[w_postprocess is a Python window. The Python code in this window converts the model output (tensor format) to more usable formats.]]></description>
          <schema>
            <fields>
              <field key="true" name="id" type="int64"/>
              <field name="image" type="blob"/>
              <field name="_nObjects_" type="int32"/>
              <field name="Object_x" type="array(dbl)"/>
              <field name="Object_y" type="array(dbl)"/>
              <field name="Object_width" type="array(dbl)"/>
              <field name="Object_height" type="array(dbl)"/>
              <field name="Object_score" type="array(dbl)"/>
              <field name="Object_labels" type="string"/>
            </fields>
          </schema>
          <copy exclude="true"><![CDATA[output]]></copy>
          <use expand="true"><![CDATA[output]]></use>
          <code><![CDATA[import esp_utils

with open("@ESP_PROJECT_HOME@/analytics/yolov7/labels.txt") as file:
    labels = [line.rstrip() for line in file]

letterbox_image_shape = (@MODEL_HEIGHT@, @MODEL_WIDTH@)
original_image_shape = (@PUBLISH_HEIGHT@, @PUBLISH_WIDTH@)

def postprocess_event(output):
    event = {}
    output = esp_utils.onnx_tensor.tensor_to_np_array(output)
    event["Object_x"] = []
    event["Object_y"] = []
    event["Object_width"] = []
    event["Object_height"] = []
    event["Object_score"] = []
    event["Object_labels"] = ""

    for object_id, object_attributes in enumerate(output):
        x1, y1, x2, y2 = object_attributes[1:5].astype(int)
        x, y, w, h = esp_utils.postprocessing.bbox_letterbox_to_original(
            (x1, y1, x2 - x1, y2 - y1), letterbox_image_shape, original_image_shape
        )
        label_id = object_attributes[5].astype(int)
        score = object_attributes[6]
        label = labels[label_id]
        
        event["Object_x"].append(float(x))
        event["Object_y"].append(float(y))
        event["Object_width"].append(float(w))
        event["Object_height"].append(float(h))
        event["Object_score"].append(float(score))
        event["Object_labels"] = f"{event['Object_labels']}{label},"
        
    event["Object_labels"] = event["Object_labels"][:-1] # remove last comma
    event["_nObjects_"] = len(output)
    return event
          ]]>          </code>
        </window-python>
        <window-object-tracker name="w_object_tracker">
          <description><![CDATA[w_object_tracker is an Object Tracker window. This window enables you to track objects over time.]]></description>
          <tracker method="iou" score-sigma-low="0.3" score-sigma-high="0.3" iou-sigma="0.5" iou-sigma2="0.3" iou-sigma-dup="0.0" velocity-vector-frames="15" max-track-lives="10" min-track-length="0" track-retention="0"/>
          <output mode="array" tracks="20"/>
          <input count="_nObjects_" score="Object_score" label="Object_labels" attributes="_Object%_attributes" label-separator="," coord-type="rect" x="Object_x" y="Object_y" width="Object_width" height="Object_height"/>
        </window-object-tracker>
        <window-counter name="w_counter">
          <description><![CDATA[w_counter is a Counter window. This window provides an indication of the overall performance.]]></description>
        </window-counter>
        <window-python events="annotate_event" name="w_annotate">
          <description><![CDATA[w_annotate is a Python window. The Python code in this window draws the predicted bounding boxes of the model on the image.]]></description>
          <schema>
            <fields>
              <field key="true" name="id" type="int64"/>
              <field name="image" type="blob"/>
            </fields>
          </schema>
          <copy><![CDATA[id]]></copy>
          <code><![CDATA[import cv2          
import esp_utils


font_face = cv2.FONT_HERSHEY_SIMPLEX
font_scale = 0.3
thickness = 1
box_color = (5, 74, 153)[::-1]  # SAS Blue (b,g,r)
margin = 2

def annotate_event(data, context):
    event = {}
    image = esp_utils.image_conversion.sas_wide_image_to_opencv_image(data['image']) 
    image = annotate_object_tracker_array(image.copy(), data)
    
    # Create a jpeg output image such that we can display it in Grafana
    image = esp_utils.image_conversion.opencv_image_to_blob_image(image)
    event['image'] = image
    return event
    

def draw_bbox(image, start_point, end_point, text):
    """Draw a bounding box"""
    cv2.rectangle(image, start_point, end_point, box_color, 1)

    if sum(box_color) / 3 < 150:
        text_color = (255, 255, 255)  # (b,g,r)
    else:
        text_color = (0, 0, 0)  # (b,g,r)
    text_size = cv2.getTextSize(text, font_face, font_scale, thickness)

    text_width = int(text_size[0][0])
    text_height = int(text_size[0][1])
    line_height = text_size[1]

    x_min, y_min = start_point
    text_x = x_min + margin
    text_y = y_min - line_height - margin

    # draw a filled rectangle around text
    cv2.rectangle(
        image,
        (text_x - margin, text_y + line_height + margin),
        (text_x + text_width + margin, text_y - text_height - margin),
        box_color,
        -1,
    )

    cv2.putText(
        image,
        text,
        (text_x, text_y),
        font_face,
        font_scale,
        text_color,
        thickness,
        cv2.LINE_AA,
    )
    return image

    
def annotate_object_tracker_array(image, data):
    """Annotate results from an object tracker window"""
    for i in range(int(data["Object_density"])):
        start_point = (int(data["Object_x"][i]), int(data["Object_y"][i]))
        end_point = (
            int(data["Object_x"][i] + data["Object_w"][i]),
            int(data["Object_y"][i] + data["Object_h"][i]),
        )
        image = draw_bbox(
            image,
            start_point,
            end_point,
            f"{data['Object_id'][i]} - {data['Object_label'].split(',')[i]} ({data['Object_score'][i]*100:.0f}%)"
        )
    return image
                    ]]>          </code>
        </window-python>
      </windows>
      <edges>
        <edge source="w_object_tracker" target="w_annotate"/>
        <edge role="data" source="w_data" target="w_score"/>
        <edge role="model" source="w_reader" target="w_score"/>
        <edge role="data" source="w_score" target="w_postprocess"/>
        <edge role="data" source="w_postprocess" target="w_object_tracker"/>
        <edge source="w_annotate" target="w_counter"/>
      </edges>
    </contquery>
  </contqueries>
</project>